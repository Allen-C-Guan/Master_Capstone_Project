{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project\n",
    "## 获取数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pylab as plt\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "\n",
    "\n",
    "import paramiko\n",
    "from stat import S_ISDIR\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# 定义一个类，表示一台远端linux主机\n",
    "class Linux(object):\n",
    "    # 通过IP, 用户名，密码，超时时间初始化一个远程Linux主机\n",
    "    def __init__(self, ip, username, password, timeout=30):\n",
    "        self.ip = ip\n",
    "        self.username = username\n",
    "        self.password = password\n",
    "        self.timeout = timeout\n",
    "        # transport和chanel\n",
    "        self.t = ''\n",
    "        self.chan = ''\n",
    "        # 链接失败的重试次数\n",
    "        self.try_times = 3\n",
    "\n",
    "    # 调用该方法连接远程主机\n",
    "    def connect(self):\n",
    "         pass\n",
    "\n",
    "    # 断开连接\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "    # 发送要执行的命令\n",
    "    def send(self, cmd):\n",
    "        pass\n",
    "\n",
    "    # get单个文件\n",
    "    def sftp_get(self, remotefile, localfile):\n",
    "        t = paramiko.Transport(sock=(self.ip, 22))\n",
    "        t.connect(username=self.username, password=self.password)\n",
    "        sftp = paramiko.SFTPClient.from_transport(t)\n",
    "        sftp.get(remotefile, localfile)\n",
    "        t.close()\n",
    "\n",
    "    # put单个文件\n",
    "    def sftp_put(self, localfile, remotefile):\n",
    "        t = paramiko.Transport(sock=(self.ip, 22))\n",
    "        t.connect(username=self.username, password=self.password)\n",
    "        sftp = paramiko.SFTPClient.from_transport(t)\n",
    "        sftp.put(localfile, remotefile)\n",
    "        t.close()\n",
    "        \n",
    "    def __get_all_files_in_remote_dir(self, sftp, remote_dir):\n",
    "        #保存文件夹文件的列表\n",
    "        all_files = list()\n",
    "\n",
    "        #去掉最后的/如果有\n",
    "        if remote_dir[-1] == \"/\":\n",
    "            remote_dir = remote_dir[0:-1]\n",
    "\n",
    "        #获取目录下的所有文件\n",
    "        files = sftp.listdir_attr(remote_dir)\n",
    "        for x in files:\n",
    "            # remote_dir目录中每一个文件或目录的完整路径\n",
    "            filename = remote_dir + '/' + x.filename\n",
    "            # 如果是目录，则递归处理该目录，\n",
    "            # 这里用到了stat库中的S_ISDIR方法，与linux中的宏的名字完全一致\n",
    "            if S_ISDIR(x.st_mode):\n",
    "                all_files.extend(self.__get_all_files_in_remote_dir(sftp, filename))\n",
    "            else:\n",
    "                all_files.append(filename)\n",
    "        return all_files \n",
    "        \n",
    "    def sftp_get_dir(self, remote_dir, local_dir):\n",
    "        t = paramiko.Transport(sock=(self.ip, 22))\n",
    "        t.connect(username=self.username, password=self.password)\n",
    "        sftp = paramiko.SFTPClient.from_transport(t)\n",
    "\n",
    "         # 获取远端linux主机上指定目录及其子目录下的所有文件\n",
    "        all_files = self.__get_all_files_in_remote_dir(sftp, remote_dir)\n",
    "        # 依次get每一个文件\n",
    "        for x in all_files:\n",
    "            filename = x.split('/')[-1]\n",
    "            local_filename = os.path.join(local_dir, filename)\n",
    "            print('loading file {}, please wait'.format(filename) )\n",
    "            sftp.get(x, local_filename)\n",
    "        \n",
    "            \n",
    "    def sftp_remove_dir(self, remote_dir):\n",
    "        t = paramiko.Transport(sock=(self.ip, 22))\n",
    "        t.connect(username=self.username, password=self.password)\n",
    "        sftp = paramiko.SFTPClient.from_transport(t)\n",
    "\n",
    "        \n",
    "         # 获取远端linux主机上指定目录及其子目录下的所有文件\n",
    "        all_files = self.__get_all_files_in_remote_dir(sftp, remote_dir)\n",
    "        # 依次remove每一个文件\n",
    "        \n",
    "        for x in all_files:\n",
    "            filename = x.split('/')[-1]\n",
    "            \n",
    "            print('removing file {}, please wait'.format(filename) )\n",
    "            sftp.remove(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置IP和路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_path = '/home/pi/camera capture'\n",
    "local_path = \"/Users/allen/Desktop/tensorflow/database/pictures\"\n",
    "host = Linux('10.0.0.164', 'pi', '123456')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下载树莓派中所有路径下的文件到本地文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file 2020_01_16_18_51_23%%182g.jpg, please wait\n",
      "loading file 2020_01_16_18_51_36%%158g.jpg, please wait\n"
     ]
    }
   ],
   "source": [
    "host.sftp_get_dir(remote_path, local_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 清空远程文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host.sftp_remove_dir(remote_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络数据的处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_5h = \"/Users/allen/Desktop/Project/trained_model/MobileNet Model_my dataset_epochs = 3.h5\"\n",
    "\n",
    "model = tf.keras.models.load_model(path_5h,custom_objects={'KerasLayer':hub.KerasLayer})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据 & 建立名字和index的关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "im_gen = ImageDataGenerator(rescale=1/255)# 这个generate每次调用只遍历一次，一个epoch\n",
    "predict_data = im_gen.flow_from_directory(\"/Users/allen/Desktop/Project/Pictures/\",\n",
    "                                                 target_size=(224, 224),\n",
    "                                                 batch_size=1,shuffle = \"false\",\n",
    "                                                )\n",
    "class_names = np.array(['Apple','Eggplant','Lemon','Mango','Orange','Peach','Pear','Pepper Green','Strawberry','Tomato','Apple_Pie','Chicken_Wings','Chocolate_Cake','Dumplings','Fish_And_Chips','French_Fries','Hamburger','Hot_Dog','Ice_Cream','Pancakes','Pizza','Steak','Sushi','Waffles'])\n",
    "name_decode = {i:class_names[i] for i in range(len(class_names))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 批量预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Mango': 1, 'Pizza': 1, 'Hamburger': 3, 'Orange': 2, 'Chicken_Wings': 2, 'Pepper Green': 1, 'Ice_Cream': 5, 'Fish_And_Chips': 1, 'Tomato': 2, 'Apple': 2}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "predicted_result = model.predict(predict_data) # 预测，\n",
    "predicted_index_labels = np.argmax(predicted_result, axis=-1)  # index_label\n",
    "# print(class_names[np.argmax(predicted_result, axis=-1)])# one-hot中最大的index拿出来，对应上class，name里按顺序放好的name\n",
    "cnt_dic = {}\n",
    "for index_label in predicted_index_labels:\n",
    "    cnt_dic[name_decode[index_label]] = cnt_dic.get(name_decode[index_label],0)+1 \n",
    "print(cnt_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3 20 16  4 11  7 18 16 18 18  4 14  9 18 16 18  0  9  0 11]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "predicted_result = model.predict(predict_data) # 预测，\n",
    "predicted_index_labels = np.argmax(predicted_result, axis=-1)  # index_label\n",
    "print(predicted_index_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
